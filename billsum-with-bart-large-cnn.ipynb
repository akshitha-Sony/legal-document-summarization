{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T03:15:30.666782Z",
     "iopub.status.busy": "2023-06-12T03:15:30.666394Z",
     "iopub.status.idle": "2023-06-12T03:15:30.675825Z",
     "shell.execute_reply": "2023-06-12T03:15:30.674820Z",
     "shell.execute_reply.started": "2023-06-12T03:15:30.666750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/billsum-processed-train/catest_processed.csv\n",
      "/kaggle/input/billsum-processed-train/ustrain_processed.csv\n",
      "/kaggle/input/billsum-processed-train/ustest_processed.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-06-12T03:15:30.679000Z",
     "iopub.status.busy": "2023-06-12T03:15:30.678325Z",
     "iopub.status.idle": "2023-06-12T03:15:30.684490Z",
     "shell.execute_reply": "2023-06-12T03:15:30.682379Z",
     "shell.execute_reply.started": "2023-06-12T03:15:30.678965Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install evaluate\n",
    "!pip install accelerate\n",
    "!pip install transformers\n",
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T03:15:30.686946Z",
     "iopub.status.busy": "2023-06-12T03:15:30.686392Z",
     "iopub.status.idle": "2023-06-12T03:15:30.694301Z",
     "shell.execute_reply": "2023-06-12T03:15:30.693342Z",
     "shell.execute_reply.started": "2023-06-12T03:15:30.686895Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from datasets import load_metric\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T03:15:30.698258Z",
     "iopub.status.busy": "2023-06-12T03:15:30.697088Z",
     "iopub.status.idle": "2023-06-12T03:15:30.704690Z",
     "shell.execute_reply": "2023-06-12T03:15:30.703654Z",
     "shell.execute_reply.started": "2023-06-12T03:15:30.698130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "BATCH_SIZE = 4\n",
    "NUM_TRAIN_EPOCHS = 4\n",
    "LEARNING_RATE = 1e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "#GRAD_ACCUMULATION_STEPS = 8\n",
    "SEED = 161\n",
    "MAX_SOURCE_LENGTH = 128\n",
    "MAX_TARGET_LENGTH = 64\n",
    "\n",
    "#give \"None\" if want all the rows\n",
    "TRAINING_DATASET_SIZE = 1600 #10K = 8k + 2k\n",
    "VALIDATION_DATASET_SIZE = 400\n",
    "TESTING_DATASET_SIZE = 400 #give None if default size is required\n",
    "DATASET_PATH = \"/kaggle/input/billsum-processed-train/ustrain_processed.csv\"\n",
    "TEST_DATASET_PATH = \"/kaggle/input/billsum-processed-train/ustest_processed.csv\"\n",
    "OUTPUT_DIR = \"/kaggle/working/model_test_2k_new_6_11_2023_9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T03:15:30.706703Z",
     "iopub.status.busy": "2023-06-12T03:15:30.706207Z",
     "iopub.status.idle": "2023-06-12T03:15:30.717184Z",
     "shell.execute_reply": "2023-06-12T03:15:30.716211Z",
     "shell.execute_reply.started": "2023-06-12T03:15:30.706669Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the prefix for the summarization task\n",
    "prefix = \"summarize: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T03:15:30.720802Z",
     "iopub.status.busy": "2023-06-12T03:15:30.720463Z",
     "iopub.status.idle": "2023-06-12T03:15:30.730588Z",
     "shell.execute_reply": "2023-06-12T03:15:30.729702Z",
     "shell.execute_reply.started": "2023-06-12T03:15:30.720769Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess function\n",
    "def preprocess_function(example):\n",
    "    inputs = prefix + example[\"clean_text\"]\n",
    "    targets = example[\"summary\"]\n",
    "    inputs_encodings = tokenizer.encode_plus(inputs, truncation=True, padding=\"max_length\", max_length=MAX_SOURCE_LENGTH)\n",
    "    targets_encodings = tokenizer.encode_plus(targets, truncation=True, padding=\"max_length\", max_length=MAX_TARGET_LENGTH)\n",
    "\n",
    "    input_ids = torch.tensor(inputs_encodings[\"input_ids\"]).to(device)\n",
    "    attention_mask = torch.tensor(inputs_encodings[\"attention_mask\"]).to(device)\n",
    "    decoder_input_ids = torch.tensor(targets_encodings[\"input_ids\"]).to(device)\n",
    "    decoder_attention_mask = torch.tensor(targets_encodings[\"attention_mask\"]).to(device)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"decoder_input_ids\": decoder_input_ids,\n",
    "        \"decoder_attention_mask\": decoder_attention_mask,\n",
    "    }\n",
    "\n",
    "# Convert the datasets to PyTorch Dataset format\n",
    "class BillSumDataset(Dataset):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return preprocess_function(self.examples[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T03:15:30.732404Z",
     "iopub.status.busy": "2023-06-12T03:15:30.731958Z",
     "iopub.status.idle": "2023-06-12T03:15:30.741716Z",
     "shell.execute_reply": "2023-06-12T03:15:30.740705Z",
     "shell.execute_reply.started": "2023-06-12T03:15:30.732372Z"
    }
   },
   "outputs": [],
   "source": [
    "output_dir = OUTPUT_DIR\n",
    "# Check if saved model and tokenizer exist\n",
    "model_path = os.path.join(output_dir)\n",
    "tokenizer_path = os.path.join(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T03:15:30.743577Z",
     "iopub.status.busy": "2023-06-12T03:15:30.743121Z",
     "iopub.status.idle": "2023-06-12T03:15:30.754680Z",
     "shell.execute_reply": "2023-06-12T03:15:30.753623Z",
     "shell.execute_reply.started": "2023-06-12T03:15:30.743544Z"
    }
   },
   "outputs": [],
   "source": [
    "# Validation function for train, eval and testing dataset\n",
    "def validate_model(model, dataloader, tokenizer):\n",
    "    model.to(device)  # Move the model to the GPU\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    #aggrigates the loss from dataloader\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        decoder_input_ids = batch[\"decoder_input_ids\"].to(device)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                            decoder_input_ids=decoder_input_ids, decoder_attention_mask=decoder_attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = loss_fn(logits.view(-1, logits.shape[-1]), decoder_input_ids.view(-1))\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T03:15:30.758654Z",
     "iopub.status.busy": "2023-06-12T03:15:30.757654Z",
     "iopub.status.idle": "2023-06-12T03:15:30.769027Z",
     "shell.execute_reply": "2023-06-12T03:15:30.768022Z",
     "shell.execute_reply.started": "2023-06-12T03:15:30.758556Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, eval_dataloader, optimizer, scheduler, loss_fn, tokenizer, output_dir):\n",
    "    model.to(device)  # Move the model to the GPU\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(NUM_TRAIN_EPOCHS):\n",
    "        total_loss = 0.0\n",
    "        print(\"Training\")\n",
    "        for batch in train_dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)  # Move input tensors to the GPU\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            decoder_input_ids = batch[\"decoder_input_ids\"].to(device)\n",
    "            decoder_attention_mask = batch[\"decoder_attention_mask\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                            decoder_input_ids=decoder_input_ids, decoder_attention_mask=decoder_attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = loss_fn(logits.view(-1, logits.shape[-1]), decoder_input_ids.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        eval_loss = validate_model(model, eval_dataloader, tokenizer)\n",
    "        print(f\"Epoch {epoch + 1} - Training Loss: {avg_loss:.4f} Evaluation Loss: {eval_loss:.4f}\")\n",
    "        \n",
    "    # Save the trained model and tokenizer\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(\"Model and tokenizer saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T03:15:30.872136Z",
     "iopub.status.busy": "2023-06-12T03:15:30.870159Z",
     "iopub.status.idle": "2023-06-12T03:15:32.724727Z",
     "shell.execute_reply": "2023-06-12T03:15:32.723649Z",
     "shell.execute_reply.started": "2023-06-12T03:15:30.872093Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Disable WandB logging\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = DATASET_PATH\n",
    "df = pd.read_csv(dataset_path)\n",
    "# Select the desired features\n",
    "df = df[[\"clean_text\", \"summary\"]]\n",
    "\n",
    "# Load the testing dataset\n",
    "test_dataset_path = TEST_DATASET_PATH\n",
    "test_df = pd.read_csv(test_dataset_path)\n",
    "test_df = test_df[:TESTING_DATASET_SIZE]  # Limit the size of the testing dataset if required\n",
    "# Convert the testing dataset to PyTorch Dataset format\n",
    "test_dataset = BillSumDataset(test_df.to_dict(orient=\"records\"))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Select a subset of the training dataset\n",
    "if TRAINING_DATASET_SIZE is not None:\n",
    "    train_df = train_df[:TRAINING_DATASET_SIZE]\n",
    "\n",
    "# Select a subset of the validation dataset\n",
    "if VALIDATION_DATASET_SIZE is not None:\n",
    "    test_df = test_df[:VALIDATION_DATASET_SIZE]\n",
    "\n",
    "train_dataset = BillSumDataset(train_df.to_dict(orient=\"records\"))\n",
    "test_dataset = BillSumDataset(test_df.to_dict(orient=\"records\"))\n",
    "\n",
    "# Create the DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "eval_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T03:15:32.727914Z",
     "iopub.status.busy": "2023-06-12T03:15:32.727546Z",
     "iopub.status.idle": "2023-06-12T03:24:55.285206Z",
     "shell.execute_reply": "2023-06-12T03:24:55.283327Z",
     "shell.execute_reply.started": "2023-06-12T03:15:32.727879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch 1 - Training Loss: 4.3761 Evaluation Loss: 4.1169\n",
      "Training\n",
      "Epoch 2 - Training Loss: 4.1376 Evaluation Loss: 4.1169\n",
      "Training\n",
      "Epoch 3 - Training Loss: 4.1391 Evaluation Loss: 4.1169\n",
      "Training\n",
      "Epoch 4 - Training Loss: 4.1394 Evaluation Loss: 4.1169\n",
      "Model and tokenizer saved.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(model_path) and os.path.exists(tokenizer_path):\n",
    "    print(\"Using saved model and tokenizer\")\n",
    "    model = BartForConditionalGeneration.from_pretrained(output_dir)\n",
    "    tokenizer = BartTokenizer.from_pretrained(output_dir)\n",
    "    model.to(device)  # Move the loaded model to the GPU\n",
    "else:\n",
    "    #use CNN trained bart from facebook for best results\n",
    "    tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "    #ConditonalGeneration is used for summarization.\n",
    "    model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "    model.to(device)  # Move the model to the GPU\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    \n",
    "    loss_fn = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "    train_model(model, train_dataloader, eval_dataloader, optimizer, scheduler, loss_fn, tokenizer, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T03:29:05.632261Z",
     "iopub.status.busy": "2023-06-12T03:29:05.631878Z",
     "iopub.status.idle": "2023-06-12T03:29:05.641305Z",
     "shell.execute_reply": "2023-06-12T03:29:05.640223Z",
     "shell.execute_reply.started": "2023-06-12T03:29:05.632229Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "#Using load_metric calculate ROGUE-1, ROGUE-2 and ROGUE-L\n",
    "def evaluate(model, dataloader, tokenizer):\n",
    "    metric = load_metric(\"rouge\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        decoder_input_ids = batch[\"decoder_input_ids\"].to(device)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                            decoder_input_ids=decoder_input_ids, decoder_attention_mask=decoder_attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Generate summaries\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=MAX_TARGET_LENGTH,\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "\n",
    "        # Decode generated summaries and reference summaries\n",
    "        generated_summaries = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        target_summaries = tokenizer.batch_decode(decoder_input_ids, skip_special_tokens=True)\n",
    "\n",
    "        # Update the ROUGE metric with the generated summaries and target summaries\n",
    "        metric.add_batch(predictions=generated_summaries, references=target_summaries)\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    rouge_scores = metric.compute()\n",
    "\n",
    "    return rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T03:29:09.555254Z",
     "iopub.status.busy": "2023-06-12T03:29:09.554892Z",
     "iopub.status.idle": "2023-06-12T03:41:57.262060Z",
     "shell.execute_reply": "2023-06-12T03:41:57.260922Z",
     "shell.execute_reply.started": "2023-06-12T03:29:09.555224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROUGE-1: 0.3541\n",
      "Train ROUGE-2: 0.1792\n",
      "Train ROUGE-L: 0.2781\n",
      "Evaluation ROUGE-1: 0.1826\n",
      "Evaluation ROUGE-2: 0.0473\n",
      "Evaluation ROUGE-L: 0.1239\n",
      "Testing ROUGE-1: 0.3453\n",
      "Testing ROUGE-2: 0.1732\n",
      "Testing ROUGE-L: 0.2701\n"
     ]
    }
   ],
   "source": [
    "train_scores = evaluate(model, train_dataloader, tokenizer)\n",
    "\n",
    "train_rouge1 = train_scores['rouge1'].mid.fmeasure\n",
    "train_rouge2 = train_scores['rouge2'].mid.fmeasure\n",
    "train_rougeL = train_scores['rougeL'].mid.fmeasure\n",
    "\n",
    "print(f\"Train ROUGE-1: {train_rouge1:.4f}\")\n",
    "print(f\"Train ROUGE-2: {train_rouge2:.4f}\")\n",
    "print(f\"Train ROUGE-L: {train_rougeL:.4f}\")\n",
    "\n",
    "eval_rouge1 = eval_scores['rouge1'].mid.fmeasure\n",
    "eval_rouge2 = eval_scores['rouge2'].mid.fmeasure\n",
    "eval_rougeL = eval_scores['rougeL'].mid.fmeasure\n",
    "\n",
    "eval_scores = evaluate(model, eval_dataloader, tokenizer)\n",
    "\n",
    "print(f\"Evaluation ROUGE-1: {eval_rouge1:.4f}\")\n",
    "print(f\"Evaluation ROUGE-2: {eval_rouge2:.4f}\")\n",
    "print(f\"Evaluation ROUGE-L: {eval_rougeL:.4f}\")\n",
    "\n",
    "test_scores = evaluate(model, test_dataloader, tokenizer)\n",
    "\n",
    "test_rouge1 = test_scores['rouge1'].mid.fmeasure\n",
    "test_rouge2 = test_scores['rouge2'].mid.fmeasure\n",
    "test_rougeL = test_scores['rougeL'].mid.fmeasure\n",
    "\n",
    "print(f\"Testing ROUGE-1: {test_rouge1:.4f}\")\n",
    "print(f\"Testing ROUGE-2: {test_rouge2:.4f}\")\n",
    "print(f\"Testing ROUGE-L: {test_rougeL:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T03:24:55.313653Z",
     "iopub.status.busy": "2023-06-12T03:24:55.313306Z",
     "iopub.status.idle": "2023-06-12T03:24:55.324147Z",
     "shell.execute_reply": "2023-06-12T03:24:55.323142Z",
     "shell.execute_reply.started": "2023-06-12T03:24:55.313620Z"
    }
   },
   "outputs": [],
   "source": [
    "#Uses model to generate the summary from the bill\n",
    "def generate_summary(model, tokenizer, text, summary, max_source_length, max_target_length, device):\n",
    "    input_encoding = tokenizer.encode_plus(text, max_length=max_source_length, truncation=True, padding='max_length',\n",
    "                                           return_tensors='pt').to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_encoding['input_ids'], attention_mask=input_encoding['attention_mask'],\n",
    "                                max_length=max_target_length, num_beams=4, early_stopping=True)\n",
    "\n",
    "    generated_summary = tokenizer.decode(output.squeeze(), skip_special_tokens=True)\n",
    "    print(\"Sample Text:\")\n",
    "    #print(text)\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Generated Summary:\")\n",
    "    print(generated_summary)\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Original Summary:\")\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T03:24:55.327555Z",
     "iopub.status.busy": "2023-06-12T03:24:55.326519Z",
     "iopub.status.idle": "2023-06-12T03:24:59.119625Z",
     "shell.execute_reply": "2023-06-12T03:24:59.118494Z",
     "shell.execute_reply.started": "2023-06-12T03:24:55.327518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Text:\n",
      "--------------------------------------------------\n",
      "Generated Summary:\n",
      "The Richard B. Russell National School Lunch Act is amended by inserting after section 19, the following: \"Section 19A. FARM TO SCHOOL PROGRAM\" The Secretary shall provide assistance, through competitive matching grants and technical assistance, to eligible entities for farm to school programs that improve access to local foods.\n",
      "--------------------------------------------------\n",
      "Original Summary:\n",
      "Farm to School Improvements Act of 2010 - Amends the Richard B. Russell National School Lunch Act to direct the Secretary of Agriculture to provide competitive matching grants to schools, nonprofit organizations, and other able entities for farm to school programs that improve the access of school lunch and breakfast program participants to local foods. Provides that each grant may include an implementation grant, training and technical assistance grant, and planning grant. Requires farm to school programs to be designed to: (1) improve the nutritional health and well being of children, (2) procure healthy local foods from small and medium-sized farms. (3) support experiential nutrition education by involving school children in farm and garden-based agricultural education activities. (4) commit public and private community stakeholders to the sustained success of such programs. And (5) increase farmers' income by facilitating their access to institutional markets. Directs the Secretary to provide grant recipients with technical assistance that includes sharing information, best practices, research, and data on existing farm to school programs.\n"
     ]
    }
   ],
   "source": [
    "#train summary of train_data[1]\n",
    "data_df = pd.read_csv(DATASET_PATH) #change to train if required\n",
    "data_df = data_df [:TRAINING_DATASET_SIZE]\n",
    "\n",
    "sample_text = data_df.loc[1, 'clean_text']\n",
    "sample_summary = data_df.loc[1, 'summary']\n",
    "\n",
    "generate_summary(model,tokenizer, sample_text, sample_summary, MAX_SOURCE_LENGTH,MAX_TARGET_LENGTH,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T03:24:59.121473Z",
     "iopub.status.busy": "2023-06-12T03:24:59.121038Z",
     "iopub.status.idle": "2023-06-12T03:25:00.623680Z",
     "shell.execute_reply": "2023-06-12T03:25:00.621875Z",
     "shell.execute_reply.started": "2023-06-12T03:24:59.121437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Text:\n",
      "--------------------------------------------------\n",
      "Generated Summary:\n",
      "This Act may be cited as the \"Small Business Expansion and Hiring Act of 2011\" This Act may also be cited to be the \" Small Business Expansion Expansion Expansion Employment Expansion Expansion Hiring Expansion Employment Employment Expansion Employment Hiring Employment Employment Employment H Employment H H Employment Employment. This Act is the\n",
      "--------------------------------------------------\n",
      "Original Summary:\n",
      "Small Business Expansion and Hiring Act of 2011 - Amends the Internal Revenue Code to allow nongovernmental employers who employ an average of fewer than 100 employees during a taxable year a retained worker tax credit until December 31, 2012, for the lesser of $4,000 or 6.2 of the wages paid to a retained worker during a period of not less than 52 consecutive weeks of employment. Limits the amount of such credit with respect to any business location of the employer to $400,000 and provides that the number of retained workers taken into account for such credit shall not exceed the excess of the number of employees of the taxpayer at the end of the taxable year over the number of such employees at the beginning of the taxable year. Defines retained worker to mean any qualified individual who was employed on any date during the taxable year for a period of not less than 52 weeks and whose wages during the last 26 weeks of such period equaled at least 80 of such wages for the first 26 weeks of such period. Defines qualified individual as any individual who: (1) begins employment after 2010 and before 2014, (2) certifies by signed affidavit that such individual has not been employed for 40 hours or more per week during the 60-day period ending on the date such individual begins employment, (3) is not replacing another employee, and (4) is not disqualified for such credit by a relationship to the employer.\n"
     ]
    }
   ],
   "source": [
    "#test summary of test_data[1]\n",
    "data_df = pd.read_csv(TEST_DATASET_PATH) #change to train if required\n",
    "data_df = data_df [:TRAINING_DATASET_SIZE]\n",
    "\n",
    "sample_text = data_df.loc[1, 'clean_text']\n",
    "sample_summary = data_df.loc[1, 'summary']\n",
    "\n",
    "generate_summary(model,tokenizer, sample_text, sample_summary, MAX_SOURCE_LENGTH,MAX_TARGET_LENGTH,device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
